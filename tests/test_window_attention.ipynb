{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec58aa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([8, 49, 96])\n",
      "Output shape: torch.Size([8, 49, 96])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.swin.window_attention import WindowAttention\n",
    "\n",
    "# Example config\n",
    "dim = 96\n",
    "window_size = (7, 7)\n",
    "num_heads = 3\n",
    "attn_dropout = 0.1\n",
    "proj_dropout = 0.2\n",
    "\n",
    "# Create the module\n",
    "attn = WindowAttention(dim=dim, window_size=window_size, num_heads=num_heads, attn_dropout=attn_dropout, proj_dropout=proj_dropout)\n",
    "\n",
    "# Dummy input\n",
    "B = 2                     # batch size\n",
    "num_windows = 4           # e.g. 4 local windows\n",
    "N = window_size[0] * window_size[1]  # tokens per window\n",
    "x = torch.randn(B * num_windows, N, dim)  # [num_windows*B, N, C]\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    out = attn(x)  # no attn_mask for plain W-MSA\n",
    "\n",
    "# Check result\n",
    "print(f\"Input shape:  {x.shape}\")\n",
    "print(f\"Output shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "455bf065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention mask shape: torch.Size([64, 49, 49])\n",
      "Input shape:  torch.Size([128, 49, 96])\n",
      "Output shape: torch.Size([128, 49, 96])\n"
     ]
    }
   ],
   "source": [
    "dim = 96\n",
    "window_size = (7, 7)\n",
    "num_heads = 3\n",
    "attn_dropout = 0.1\n",
    "proj_dropout = 0.2\n",
    "\n",
    "# Create the attention module\n",
    "attn = WindowAttention(dim=dim, window_size=window_size, num_heads=num_heads, attn_dropout=attn_dropout, proj_dropout=proj_dropout)\n",
    "\n",
    "# ---- Dummy input ----\n",
    "B = 2                                 # batch size\n",
    "H = W = 56                            # fake image height & width\n",
    "N = window_size[0] * window_size[1]   # 49 tokens per window\n",
    "num_windows = (H // window_size[0]) * (W // window_size[1])\n",
    "x = torch.randn(B * num_windows, N, dim)\n",
    "\n",
    "# ---- Build shifted-window attention mask ----\n",
    "def build_attn_mask(H, W, window_size, shift_size):\n",
    "    img_mask = torch.zeros((1, H, W, 1))\n",
    "    cnt = 0\n",
    "    h_slices = (\n",
    "        slice(0, -window_size),\n",
    "        slice(-window_size, -shift_size),\n",
    "        slice(-shift_size, None),\n",
    "    )\n",
    "    w_slices = (\n",
    "        slice(0, -window_size),\n",
    "        slice(-window_size, -shift_size),\n",
    "        slice(-shift_size, None),\n",
    "    )\n",
    "    for h in h_slices:\n",
    "        for w in w_slices:\n",
    "            img_mask[:, h, w, :] = cnt\n",
    "            cnt += 1\n",
    "\n",
    "    # partition into windows\n",
    "    def window_partition(x, window_size):\n",
    "        B, H, W, C = x.shape\n",
    "        x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "        x = x.permute(0, 1, 3, 2, 4, 5).contiguous()\n",
    "        return x.view(-1, window_size * window_size, C)\n",
    "\n",
    "    mask_windows = window_partition(img_mask, window_size).view(-1, N)\n",
    "    attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "    attn_mask = attn_mask.masked_fill(attn_mask != 0, -100.0).masked_fill(attn_mask == 0, 0.0)\n",
    "    return attn_mask\n",
    "\n",
    "shift_size = window_size[0] // 2\n",
    "attn_mask = build_attn_mask(H, W, window_size[0], shift_size)\n",
    "\n",
    "print(\"Attention mask shape:\", attn_mask.shape)\n",
    "\n",
    "# ---- Forward pass ----\n",
    "with torch.no_grad():\n",
    "    out = attn(x, attn_mask=attn_mask)\n",
    "\n",
    "print(f\"Input shape:  {x.shape}\")\n",
    "print(f\"Output shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa4c43ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coords:\n",
      "tensor([[[0, 0],\n",
      "         [1, 1]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [0, 1]]])\n",
      "Relative coords:\n",
      "tensor([[[ 0,  0, -1, -1],\n",
      "         [ 0,  0, -1, -1],\n",
      "         [ 1,  1,  0,  0],\n",
      "         [ 1,  1,  0,  0]],\n",
      "\n",
      "        [[ 0, -1,  0, -1],\n",
      "         [ 1,  0,  1,  0],\n",
      "         [ 0, -1,  0, -1],\n",
      "         [ 1,  0,  1,  0]]])\n",
      "Relative processed coords:\n",
      "tensor([[[3, 1],\n",
      "         [3, 0],\n",
      "         [0, 1],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[3, 2],\n",
      "         [3, 1],\n",
      "         [0, 2],\n",
      "         [0, 1]],\n",
      "\n",
      "        [[6, 1],\n",
      "         [6, 0],\n",
      "         [3, 1],\n",
      "         [3, 0]],\n",
      "\n",
      "        [[6, 2],\n",
      "         [6, 1],\n",
      "         [3, 2],\n",
      "         [3, 1]]])\n",
      "Relative position index:\n",
      "tensor([[4, 3, 1, 0],\n",
      "        [5, 4, 2, 1],\n",
      "        [7, 6, 4, 3],\n",
      "        [8, 7, 5, 4]])\n"
     ]
    }
   ],
   "source": [
    "window_size = (2,2)\n",
    "\n",
    "coords_h = torch.arange(window_size[0])\n",
    "coords_w = torch.arange(window_size[1])\n",
    "coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing='ij'))  # 2, Wh, Ww\n",
    "print(\"Coords:\")\n",
    "print(coords)\n",
    "coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "print(\"Relative coords:\")\n",
    "print(relative_coords)\n",
    "relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "relative_coords[:, :, 0] += window_size[0] - 1  # shift to start from 0\n",
    "relative_coords[:, :, 1] += window_size[1] - 1\n",
    "relative_coords[:, :, 0] *= 2 * window_size[1] - 1\n",
    "print(\"Relative processed coords:\")\n",
    "print(relative_coords)\n",
    "relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "print(\"Relative position index:\")\n",
    "print(relative_position_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
