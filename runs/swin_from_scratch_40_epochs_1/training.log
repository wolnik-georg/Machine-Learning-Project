2025-12-22 06:11:30,048 - INFO - Logging initialized. Log file: runs/run_233/training.log
2025-12-22 06:11:30,235 - INFO - Experiment directory: runs/run_233
2025-12-22 06:11:30,237 - INFO - Setting random seeds for reproducibility (seed: 42)...
2025-12-22 06:11:30,301 - INFO - ✅ All seeds set to 42 (deterministic=False)
2025-12-22 06:11:30,760 - INFO - GPU memory cleared at startup. Available: 23.6GB
2025-12-22 06:11:30,762 - INFO - Using device: cuda
2025-12-22 06:11:30,763 - INFO - Training configuration: epochs=40, warmup=3, lr=0.0005
2025-12-22 06:11:30,765 - INFO - SWIN configuration: variant=tiny, use_shifted_window=True, use_relative_bias=True, use_absolute_pos_embed=False, use_hierarchical_merge=False, use_gradient_checkpointing=True
2025-12-22 06:11:30,766 - INFO - SWIN details: embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24], window_size=7
2025-12-22 06:11:30,768 - INFO - Loading dataset...
2025-12-22 06:11:30,773 - INFO - Starting ImageNet data loading from root: /
2025-12-22 06:11:30,774 - INFO - Resolved root path: /
2025-12-22 06:11:30,775 - INFO - Root path exists: True
2025-12-22 06:11:30,777 - INFO - Root path is dir: True
2025-12-22 06:11:30,788 - INFO - Contents of /: ['/.exec', '/.run', '/.shell', '/.singularity.d', '/.test', '/bin', '/boot', '/dev', '/environment', '/etc', '/home', '/lib', '/lib64', '/media', '/mnt', '/opt', '/proc', '/requirements.txt', '/root', '/run', '/sbin', '/singularity', '/srv', '/sys', '/tmp', '/usr', '/var', '/meta', '/train_set', '/train_set_small', '/val_set', '/val_set_unlabeled']
2025-12-22 06:11:30,790 - INFO - Expected train_dir: /train_set, exists: True
2025-12-22 06:11:30,791 - INFO - Expected val_dir: /val_set, exists: True
2025-12-22 06:11:45,176 - INFO - Loaded ImageNet data from /: train=1281167, val=50000
2025-12-22 06:11:45,543 - INFO - Dataset loaded: train=100000 samples (782 batches), val=50000 samples (391 batches), test=50000 samples (391 batches)
2025-12-22 06:11:50,787 - INFO - Training SWIN from scratch
2025-12-22 06:11:50,792 - INFO - Initializing SWIN model from scratch...
2025-12-22 06:11:50,793 - INFO - Model architecture: SWIN
2025-12-22 06:11:50,794 - INFO - Model config: {'type': 'swin', 'variant': 'tiny', 'patch_size': 4, 'embed_dim': 96, 'depths': [2, 2, 6, 2], 'num_heads': [3, 6, 12, 24], 'window_size': 7, 'mlp_ratio': 4.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'projection_dropout': 0.0, 'drop_path_rate': 0.08, 'use_shifted_window': True, 'use_relative_bias': True, 'use_absolute_pos_embed': False, 'use_hierarchical_merge': False, 'use_gradient_checkpointing': True}
2025-12-22 06:11:51,879 - INFO - Model created with random initialization
2025-12-22 06:11:51,881 - INFO - Total parameters: 28,288,354
2025-12-22 06:11:51,882 - INFO - Trainable parameters: 28,288,354
2025-12-22 06:11:51,970 - INFO - Starting from-scratch training...
2025-12-22 06:11:51,972 - INFO - Optimizer: training all model parameters
2025-12-22 06:11:51,976 - INFO - LR Scheduler: cosine with 3 warmup epochs
2025-12-22 06:11:51,978 - INFO - Starting training...
2025-12-22 07:03:51,284 - INFO - Epoch 1/40: LR: 0.000170
2025-12-22 07:03:51,314 - INFO - Epoch 1/40: Train Loss: 6.8849, Val Loss: 6.7706, Val Acc: 0.46%
2025-12-22 07:48:49,092 - INFO - Epoch 2/40: LR: 0.000335
2025-12-22 07:48:49,118 - INFO - Epoch 2/40: Train Loss: 6.7454, Val Loss: 6.5014, Val Acc: 0.94%
2025-12-22 08:34:56,097 - INFO - Epoch 3/40: LR: 0.000500
2025-12-22 08:34:56,171 - INFO - Epoch 3/40: Train Loss: 6.4500, Val Loss: 6.2015, Val Acc: 1.47%
2025-12-22 09:19:16,732 - INFO - Epoch 4/40: LR: 0.000499
2025-12-22 09:19:16,735 - INFO - Epoch 4/40: Train Loss: 6.2548, Val Loss: 5.9632, Val Acc: 2.24%
2025-12-22 10:03:44,795 - INFO - Epoch 5/40: LR: 0.000497
2025-12-22 10:18:28,237 - INFO - Epoch 5/40: Train Loss: 6.0858, Val Loss: 5.8042, Val Acc: 2.91%, Test Loss: 5.8042, Test Acc: 2.91%
2025-12-22 11:02:58,505 - INFO - Epoch 6/40: LR: 0.000493
2025-12-22 11:02:58,522 - INFO - Epoch 6/40: Train Loss: 5.9519, Val Loss: 5.6380, Val Acc: 3.90%
2025-12-22 11:49:46,375 - INFO - Epoch 7/40: LR: 0.000487
2025-12-22 11:49:46,427 - INFO - Epoch 7/40: Train Loss: 5.8309, Val Loss: 5.4646, Val Acc: 5.14%
2025-12-22 12:36:15,532 - INFO - Epoch 8/40: LR: 0.000480
2025-12-22 12:36:15,571 - INFO - Epoch 8/40: Train Loss: 5.7012, Val Loss: 5.3386, Val Acc: 6.15%
2025-12-22 13:21:22,418 - INFO - Epoch 9/40: LR: 0.000471
2025-12-22 13:21:22,444 - INFO - Epoch 9/40: Train Loss: 5.5953, Val Loss: 5.2179, Val Acc: 7.01%
2025-12-22 14:07:11,999 - INFO - Epoch 10/40: LR: 0.000461
2025-12-22 14:21:36,056 - INFO - Epoch 10/40: Train Loss: 5.4983, Val Loss: 5.1257, Val Acc: 7.76%, Test Loss: 5.1257, Test Acc: 7.76%
2025-12-22 14:21:36,086 - INFO - Saving checkpoint for epoch 10...
2025-12-22 14:21:37,682 - INFO - ✅ Checkpoint saved: runs/run_233/checkpoint_epoch_10.pth
2025-12-22 15:05:32,517 - INFO - Epoch 11/40: LR: 0.000450
2025-12-22 15:05:32,560 - INFO - Epoch 11/40: Train Loss: 5.3936, Val Loss: 5.0444, Val Acc: 9.01%
2025-12-22 15:50:09,319 - INFO - Epoch 12/40: LR: 0.000437
2025-12-22 15:50:09,772 - INFO - Epoch 12/40: Train Loss: 5.2966, Val Loss: 4.9010, Val Acc: 10.13%
2025-12-22 16:34:44,850 - INFO - Epoch 13/40: LR: 0.000424
2025-12-22 16:34:44,957 - INFO - Epoch 13/40: Train Loss: 5.1931, Val Loss: 4.8455, Val Acc: 10.70%
2025-12-22 17:20:17,611 - INFO - Epoch 14/40: LR: 0.000409
2025-12-22 17:20:17,721 - INFO - Epoch 14/40: Train Loss: 5.0985, Val Loss: 4.7053, Val Acc: 12.38%
2025-12-22 18:04:54,113 - INFO - Epoch 15/40: LR: 0.000393
2025-12-22 18:19:22,861 - INFO - Epoch 15/40: Train Loss: 5.0033, Val Loss: 4.6247, Val Acc: 13.52%, Test Loss: 4.6247, Test Acc: 13.52%
2025-12-22 19:03:35,405 - INFO - Epoch 16/40: LR: 0.000376
2025-12-22 19:03:35,472 - INFO - Epoch 16/40: Train Loss: 4.9201, Val Loss: 4.5438, Val Acc: 14.22%
2025-12-22 19:47:54,120 - INFO - Epoch 17/40: LR: 0.000359
2025-12-22 19:47:54,165 - INFO - Epoch 17/40: Train Loss: 4.8391, Val Loss: 4.4489, Val Acc: 14.97%
2025-12-22 20:32:21,922 - INFO - Epoch 18/40: LR: 0.000341
2025-12-22 20:32:21,965 - INFO - Epoch 18/40: Train Loss: 4.7569, Val Loss: 4.4194, Val Acc: 15.42%
2025-12-22 21:16:06,406 - INFO - Epoch 19/40: LR: 0.000322
2025-12-22 21:16:06,445 - INFO - Epoch 19/40: Train Loss: 4.6720, Val Loss: 4.3402, Val Acc: 16.35%
2025-12-22 22:00:52,133 - INFO - Epoch 20/40: LR: 0.000304
2025-12-22 22:15:13,322 - INFO - Epoch 20/40: Train Loss: 4.5939, Val Loss: 4.2961, Val Acc: 17.07%, Test Loss: 4.2961, Test Acc: 17.07%
2025-12-22 22:15:13,325 - INFO - Saving checkpoint for epoch 20...
2025-12-22 22:15:14,785 - INFO - ✅ Checkpoint saved: runs/run_233/checkpoint_epoch_20.pth
2025-12-22 22:59:16,248 - INFO - Epoch 21/40: LR: 0.000285
2025-12-22 22:59:16,292 - INFO - Epoch 21/40: Train Loss: 4.5076, Val Loss: 4.2161, Val Acc: 17.91%
2025-12-22 23:43:19,741 - INFO - Epoch 22/40: LR: 0.000265
2025-12-22 23:43:19,778 - INFO - Epoch 22/40: Train Loss: 4.4354, Val Loss: 4.1642, Val Acc: 18.83%
2025-12-23 00:27:11,576 - INFO - Epoch 23/40: LR: 0.000246
2025-12-23 00:27:11,606 - INFO - Epoch 23/40: Train Loss: 4.3533, Val Loss: 4.1137, Val Acc: 19.49%
2025-12-23 01:12:19,554 - INFO - Epoch 24/40: LR: 0.000228
2025-12-23 01:12:19,585 - INFO - Epoch 24/40: Train Loss: 4.2861, Val Loss: 4.0472, Val Acc: 20.45%
2025-12-23 01:56:47,050 - INFO - Epoch 25/40: LR: 0.000209
2025-12-23 02:11:13,182 - INFO - Epoch 25/40: Train Loss: 4.2228, Val Loss: 3.9954, Val Acc: 21.18%, Test Loss: 3.9954, Test Acc: 21.18%
2025-12-23 02:56:23,651 - INFO - Epoch 26/40: LR: 0.000191
2025-12-23 02:56:23,698 - INFO - Epoch 26/40: Train Loss: 4.1544, Val Loss: 3.9631, Val Acc: 21.49%
2025-12-23 03:40:53,751 - INFO - Epoch 27/40: LR: 0.000174
2025-12-23 03:40:53,803 - INFO - Epoch 27/40: Train Loss: 4.0770, Val Loss: 3.9004, Val Acc: 22.39%
2025-12-23 04:24:36,223 - INFO - Epoch 28/40: LR: 0.000157
2025-12-23 04:24:36,261 - INFO - Epoch 28/40: Train Loss: 4.0112, Val Loss: 3.8605, Val Acc: 23.15%
2025-12-23 05:08:32,155 - INFO - Epoch 29/40: LR: 0.000141
2025-12-23 05:08:32,195 - INFO - Epoch 29/40: Train Loss: 3.9504, Val Loss: 3.8335, Val Acc: 23.42%
2025-12-23 05:53:11,497 - INFO - Epoch 30/40: LR: 0.000126
2025-12-23 06:07:39,212 - INFO - Epoch 30/40: Train Loss: 3.8875, Val Loss: 3.7783, Val Acc: 24.12%, Test Loss: 3.7783, Test Acc: 24.12%
2025-12-23 06:07:39,221 - INFO - Saving checkpoint for epoch 30...
2025-12-23 06:07:40,546 - INFO - ✅ Checkpoint saved: runs/run_233/checkpoint_epoch_30.pth
2025-12-23 06:51:35,861 - INFO - Epoch 31/40: LR: 0.000113
2025-12-23 06:51:35,875 - INFO - Epoch 31/40: Train Loss: 3.8318, Val Loss: 3.7779, Val Acc: 24.37%
2025-12-23 07:36:24,649 - INFO - Epoch 32/40: LR: 0.000100
2025-12-23 07:36:24,686 - INFO - Epoch 32/40: Train Loss: 3.7881, Val Loss: 3.7189, Val Acc: 24.91%
2025-12-23 08:20:47,035 - INFO - Epoch 33/40: LR: 0.000089
2025-12-23 08:20:47,054 - INFO - Epoch 33/40: Train Loss: 3.7312, Val Loss: 3.6930, Val Acc: 25.50%
2025-12-23 09:05:46,121 - INFO - Epoch 34/40: LR: 0.000079
2025-12-23 09:05:46,172 - INFO - Epoch 34/40: Train Loss: 3.6986, Val Loss: 3.6690, Val Acc: 25.84%
2025-12-23 09:49:32,569 - INFO - Epoch 35/40: LR: 0.000070
2025-12-23 10:03:56,958 - INFO - Epoch 35/40: Train Loss: 3.6552, Val Loss: 3.6674, Val Acc: 25.92%, Test Loss: 3.6674, Test Acc: 25.92%
2025-12-23 10:47:51,574 - INFO - Epoch 36/40: LR: 0.000063
2025-12-23 10:47:51,608 - INFO - Epoch 36/40: Train Loss: 3.6160, Val Loss: 3.6529, Val Acc: 26.08%
2025-12-23 11:32:14,137 - INFO - Epoch 37/40: LR: 0.000057
2025-12-23 11:32:14,165 - INFO - Epoch 37/40: Train Loss: 3.5822, Val Loss: 3.6385, Val Acc: 26.33%
2025-12-23 12:16:14,210 - INFO - Epoch 38/40: LR: 0.000053
2025-12-23 12:16:14,241 - INFO - Epoch 38/40: Train Loss: 3.5553, Val Loss: 3.6205, Val Acc: 26.48%
2025-12-23 13:01:22,029 - INFO - Epoch 39/40: LR: 0.000051
2025-12-23 13:01:22,056 - INFO - Epoch 39/40: Train Loss: 3.5380, Val Loss: 3.6130, Val Acc: 26.95%
2025-12-23 13:45:02,959 - INFO - Epoch 40/40: LR: 0.000050
2025-12-23 13:59:30,237 - INFO - Epoch 40/40: Train Loss: 3.5061, Val Loss: 3.6157, Val Acc: 26.73%, Test Loss: 3.6157, Test Acc: 26.73%
2025-12-23 13:59:30,971 - INFO - Saving checkpoint for epoch 40...
2025-12-23 13:59:32,543 - INFO - ✅ Checkpoint saved: runs/run_233/checkpoint_epoch_40.pth
2025-12-23 13:59:32,545 - INFO - Training completed!
2025-12-23 13:59:32,548 - INFO - Training completed!
2025-12-23 13:59:32,550 - INFO - Generating training curves...
2025-12-23 13:59:36,873 - INFO - Too many classes (1000) for per-class plotting, skipping
2025-12-23 13:59:36,875 - INFO - Training curves saved as separate images with base name 'runs/run_233/training_curves_from_scratch'
2025-12-23 13:59:36,876 - INFO - Generating confusion matrix on test set...
2025-12-23 15:02:54,489 - INFO - Performing final evaluation of from_scratch model on test set...
2025-12-23 15:19:16,768 - INFO - Final Test Results of from_scratch model: Loss: 3.6157, Accuracy: 26.73%
2025-12-23 15:19:16,798 - INFO - Generating LR schedule plot of from_scratch model...
2025-12-23 15:19:17,632 - INFO - LR schedule plot saved to 'runs/run_233/lr_schedule_from_scratch.png'
2025-12-23 15:19:17,634 - INFO - 
Final Test Results:
2025-12-23 15:19:17,637 - INFO - Loss: 3.6157
2025-12-23 15:19:17,639 - INFO - Accuracy: 26.73%
2025-12-23 15:19:17,641 - INFO - Precision: 26.20%
2025-12-23 15:19:17,643 - INFO - Recall: 26.73%
2025-12-23 15:19:17,645 - INFO - F1 Score: 25.31%
2025-12-23 15:19:18,415 - INFO - Experiment completed. Results saved to runs/run_233/results_from_scratch.json
2025-12-23 15:19:18,437 - INFO - Experiment completed. Metadata saved to runs/run_233/metadata_from_scratch.json
2025-12-23 15:19:19,048 - INFO - ✅ Model weights saved: runs/run_233/final_model_from_scratch_weights.pth
2025-12-23 15:19:19,053 - INFO - Final model saved: runs/run_233/final_model_from_scratch_weights.pth
2025-12-23 15:19:19,055 - INFO - Final model metadata saved: runs/run_233/final_model_from_scratch_metadata.json
2025-12-23 15:19:19,057 - INFO - === FROM-SCRATCH RESULTS (IMAGENET) ===
2025-12-23 15:19:19,058 - INFO - Final Accuracy: 26.73%
2025-12-23 15:19:19,060 - INFO - Final F1 Score: 25.31%
2025-12-23 15:19:19,066 - INFO - from_scratch experiment completed successfully!
