2025-12-13 13:35:38,075 - INFO - Logging initialized. Log file: runs/run_175/training.log
2025-12-13 13:35:38,077 - INFO - Experiment directory: runs/run_175
2025-12-13 13:35:38,078 - INFO - Setting random seeds for reproducibility (seed: 42)...
2025-12-13 13:35:38,358 - INFO - Random seeds set to 42 (deterministic=False)
2025-12-13 13:35:38,607 - INFO - GPU memory cleared at startup. Available: 23.5GB
2025-12-13 13:35:38,609 - INFO - Using device: cuda
2025-12-13 13:35:38,611 - INFO - Training configuration: epochs=50, warmup=3, lr=0.0006
2025-12-13 13:35:38,612 - INFO - SWIN configuration: variant=tiny, use_shifted_window=True, use_relative_bias=True, use_absolute_pos_embed=False, use_hierarchical_merge=False
2025-12-13 13:35:38,613 - INFO - SWIN details: embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24], window_size=7
2025-12-13 13:35:38,615 - INFO - Loading dataset...
2025-12-13 13:35:41,741 - INFO - Dataset loaded: train=41667 samples (163 batches), val=8333 samples (33 batches), test=10000 samples (40 batches)
2025-12-13 13:35:45,403 - INFO - Training Swin-Tiny from scratch
2025-12-13 13:35:45,404 - INFO - Initializing model from scratch...
2025-12-13 13:35:45,406 - INFO - Model architecture: Swin-Tiny
2025-12-13 13:35:45,407 - INFO - Model config: embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24], window_size=7, use_shifted_window=True, use_relative_bias=True, use_absolute_pos_embed=False, use_hierarchical_merge=False
2025-12-13 13:35:46,089 - INFO - Model created with random initialization
2025-12-13 13:35:46,091 - INFO - Total parameters: 27,596,254
2025-12-13 13:35:46,092 - INFO - Trainable parameters: 27,596,254
2025-12-13 13:35:46,143 - INFO - Starting from-scratch training...
2025-12-13 13:35:46,145 - INFO - Optimizer: training all model parameters
2025-12-13 13:35:46,148 - INFO - LR Scheduler: cosine with 3 warmup epochs
2025-12-13 13:35:46,149 - INFO - Starting training...
2025-12-13 13:35:49,409 - ERROR - Experiment failed with error: CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacity of 23.46 GiB of which 234.88 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 196.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-13 13:35:49,412 - ERROR - Full traceback:
Traceback (most recent call last):
  File "/home/pml04/swin_transformer/Machine-Learning-Project/main.py", line 221, in main
    run_from_scratch(
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/pipelines/from_scratch.py", line 235, in run_from_scratch
    criterion, lr_history, metrics_history = _train_single_model(
                                             ^^^^^^^^^^^^^^^^^^^^
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/pipelines/from_scratch.py", line 135, in _train_single_model
    run_training_loop(
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/training/trainer.py", line 165, in run_training_loop
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/training/trainer.py", line 64, in train_one_epoch
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/models/model_wrapper.py", line 35, in forward
    features = self.encoder(x)
               ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/models/swin/swin_transformer_model.py", line 177, in forward
    x = self.forward_features(x)
        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/models/swin/swin_transformer_model.py", line 171, in forward_features
    x = layer(x)
        ^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/models/swin/basic_layer.py", line 201, in forward
    x = block(x)
        ^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/models/swin/swin_transformer_block.py", line 246, in forward
    x = x + self.drop_path2(self.mlp(self.norm2(x)))
                            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pml04/swin_transformer/Machine-Learning-Project/src/models/swin/mlp.py", line 56, in forward
    x = self.act(x)
        ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 816, in forward
    return F.gelu(input, approximate=self.approximate)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacity of 23.46 GiB of which 234.88 MiB is free. Including non-PyTorch memory, this process has 23.23 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 196.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
